{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "# https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification\n",
    "csv_file = 'Training_set.csv'\n",
    "data = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map images to their labels\n",
    "image_dir = 'train'\n",
    "data['filepath'] = data['filename'].apply(lambda x: os.path.join(image_dir, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode class names to integers\n",
    "class_names = data['label'].unique()\n",
    "class_to_index = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "data['label'] = data['label'].map(class_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing utility function\n",
    "def process_image(file_path, label):\n",
    "    # Load the image\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode the JPEG image\n",
    "    img = tf.image.resize(img, [64, 64])  # Resize the image\n",
    "    img = img / 255.0  # Normalize pixel values\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets\n",
    "def create_dataset(dataframe):\n",
    "    file_paths = dataframe['filepath'].values\n",
    "    labels = dataframe['label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=len(dataframe)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = create_dataset(train_data)\n",
    "val_dataset = create_dataset(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=40,  # Random rotation\n",
    "    width_shift_range=0.2,  # Random shift along the width\n",
    "    height_shift_range=0.2  # Random shift along the height\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Dropout layer to reduce overfitting\n",
    "    layers.Dense(len(class_names), activation='softmax')  # Output layer for multiclass classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # For integer class labels\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate scheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return float(lr)  # Ensure the return type is float\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(-0.1))  # Adjust learning rate and return as float\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,  # Try 30 or more epochs\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[lr_scheduler]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def predict_label(image_path, model=model, class_names=class_names):\n",
    "    \"\"\"\n",
    "    Predict the label of an input image using the trained model.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Path to the input image.\n",
    "        model (tf.keras.Model): Trained TensorFlow/Keras model.\n",
    "        class_names (list): List of class names in order of their encoded labels.\n",
    "\n",
    "    Returns:\n",
    "        str: Predicted label name for the input image.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the image\n",
    "    img = load_img(image_path, target_size=(64, 64))  # Load the image and resize it to 64x64\n",
    "    img_array = img_to_array(img)  # Convert the image to a numpy array\n",
    "    img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension (shape: [1, 64, 64, 3])\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_array)  # Returns an array of probabilities\n",
    "    predicted_index = np.argmax(predictions)  # Get the index of the highest probability\n",
    "    predicted_label = class_names[predicted_index]  # Map index to the class name\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "for i in range(1,11):\n",
    "    print(predict_label('train\\Image_' + str(i) + '.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
